import {
  PostProcessManager,
  RenderingManager,
  SmartArray
} from "./chunk-2GNVGG7Y.js";
import {
  Texture
} from "./chunk-AHMKO7Z3.js";
import {
  Color3,
  SerializationHelper,
  __decorate,
  serialize,
  serializeAsColor4
} from "./chunk-LJWPR2K5.js";
import {
  Matrix,
  TmpVectors,
  ToLinearSpace,
  Vector2,
  Vector3,
  _ObserveArray
} from "./chunk-GCXGXOND.js";
import {
  DrawWrapper
} from "./chunk-NSQCR3LX.js";
import {
  Clamp
} from "./chunk-537VGFRK.js";
import {
  GetClass,
  RegisterClass
} from "./chunk-4LFNXJGH.js";
import {
  AbstractEngine,
  Effect,
  FloorPOT,
  GetExponentOfTwo,
  NearestPOT
} from "./chunk-ULQUZGBY.js";
import {
  Observable
} from "./chunk-TS7CPY6B.js";
import {
  Logger
} from "./chunk-RP2ILEGM.js";

// node_modules/@babylonjs/core/Maths/sphericalPolynomial.js
var SH3ylmBasisConstants = [
  Math.sqrt(1 / (4 * Math.PI)),
  -Math.sqrt(3 / (4 * Math.PI)),
  Math.sqrt(3 / (4 * Math.PI)),
  -Math.sqrt(3 / (4 * Math.PI)),
  Math.sqrt(15 / (4 * Math.PI)),
  -Math.sqrt(15 / (4 * Math.PI)),
  Math.sqrt(5 / (16 * Math.PI)),
  -Math.sqrt(15 / (4 * Math.PI)),
  Math.sqrt(15 / (16 * Math.PI))
  // l22
];
var SH3ylmBasisTrigonometricTerms = [
  () => 1,
  (direction) => direction.y,
  (direction) => direction.z,
  (direction) => direction.x,
  (direction) => direction.x * direction.y,
  (direction) => direction.y * direction.z,
  (direction) => 3 * direction.z * direction.z - 1,
  (direction) => direction.x * direction.z,
  (direction) => direction.x * direction.x - direction.y * direction.y
  // l22
];
var applySH3 = (lm, direction) => {
  return SH3ylmBasisConstants[lm] * SH3ylmBasisTrigonometricTerms[lm](direction);
};
var SHCosKernelConvolution = [Math.PI, 2 * Math.PI / 3, 2 * Math.PI / 3, 2 * Math.PI / 3, Math.PI / 4, Math.PI / 4, Math.PI / 4, Math.PI / 4, Math.PI / 4];
var SphericalHarmonics = class _SphericalHarmonics {
  constructor() {
    this.preScaled = false;
    this.l00 = Vector3.Zero();
    this.l1_1 = Vector3.Zero();
    this.l10 = Vector3.Zero();
    this.l11 = Vector3.Zero();
    this.l2_2 = Vector3.Zero();
    this.l2_1 = Vector3.Zero();
    this.l20 = Vector3.Zero();
    this.l21 = Vector3.Zero();
    this.l22 = Vector3.Zero();
  }
  /**
   * Adds a light to the spherical harmonics
   * @param direction the direction of the light
   * @param color the color of the light
   * @param deltaSolidAngle the delta solid angle of the light
   */
  addLight(direction, color, deltaSolidAngle) {
    TmpVectors.Vector3[0].set(color.r, color.g, color.b);
    const colorVector = TmpVectors.Vector3[0];
    const c = TmpVectors.Vector3[1];
    colorVector.scaleToRef(deltaSolidAngle, c);
    c.scaleToRef(applySH3(0, direction), TmpVectors.Vector3[2]);
    this.l00.addInPlace(TmpVectors.Vector3[2]);
    c.scaleToRef(applySH3(1, direction), TmpVectors.Vector3[2]);
    this.l1_1.addInPlace(TmpVectors.Vector3[2]);
    c.scaleToRef(applySH3(2, direction), TmpVectors.Vector3[2]);
    this.l10.addInPlace(TmpVectors.Vector3[2]);
    c.scaleToRef(applySH3(3, direction), TmpVectors.Vector3[2]);
    this.l11.addInPlace(TmpVectors.Vector3[2]);
    c.scaleToRef(applySH3(4, direction), TmpVectors.Vector3[2]);
    this.l2_2.addInPlace(TmpVectors.Vector3[2]);
    c.scaleToRef(applySH3(5, direction), TmpVectors.Vector3[2]);
    this.l2_1.addInPlace(TmpVectors.Vector3[2]);
    c.scaleToRef(applySH3(6, direction), TmpVectors.Vector3[2]);
    this.l20.addInPlace(TmpVectors.Vector3[2]);
    c.scaleToRef(applySH3(7, direction), TmpVectors.Vector3[2]);
    this.l21.addInPlace(TmpVectors.Vector3[2]);
    c.scaleToRef(applySH3(8, direction), TmpVectors.Vector3[2]);
    this.l22.addInPlace(TmpVectors.Vector3[2]);
  }
  /**
   * Scales the spherical harmonics by the given amount
   * @param scale the amount to scale
   */
  scaleInPlace(scale) {
    this.l00.scaleInPlace(scale);
    this.l1_1.scaleInPlace(scale);
    this.l10.scaleInPlace(scale);
    this.l11.scaleInPlace(scale);
    this.l2_2.scaleInPlace(scale);
    this.l2_1.scaleInPlace(scale);
    this.l20.scaleInPlace(scale);
    this.l21.scaleInPlace(scale);
    this.l22.scaleInPlace(scale);
  }
  /**
   * Convert from incident radiance (Li) to irradiance (E) by applying convolution with the cosine-weighted hemisphere.
   *
   * ```
   * E_lm = A_l * L_lm
   * ```
   *
   * In spherical harmonics this convolution amounts to scaling factors for each frequency band.
   * This corresponds to equation 5 in "An Efficient Representation for Irradiance Environment Maps", where
   * the scaling factors are given in equation 9.
   */
  convertIncidentRadianceToIrradiance() {
    this.l00.scaleInPlace(SHCosKernelConvolution[0]);
    this.l1_1.scaleInPlace(SHCosKernelConvolution[1]);
    this.l10.scaleInPlace(SHCosKernelConvolution[2]);
    this.l11.scaleInPlace(SHCosKernelConvolution[3]);
    this.l2_2.scaleInPlace(SHCosKernelConvolution[4]);
    this.l2_1.scaleInPlace(SHCosKernelConvolution[5]);
    this.l20.scaleInPlace(SHCosKernelConvolution[6]);
    this.l21.scaleInPlace(SHCosKernelConvolution[7]);
    this.l22.scaleInPlace(SHCosKernelConvolution[8]);
  }
  /**
   * Convert from irradiance to outgoing radiance for Lambertian BDRF, suitable for efficient shader evaluation.
   *
   * ```
   * L = (1/pi) * E * rho
   * ```
   *
   * This is done by an additional scale by 1/pi, so is a fairly trivial operation but important conceptually.
   */
  convertIrradianceToLambertianRadiance() {
    this.scaleInPlace(1 / Math.PI);
  }
  /**
   * Integrates the reconstruction coefficients directly in to the SH preventing further
   * required operations at run time.
   *
   * This is simply done by scaling back the SH with Ylm constants parameter.
   * The trigonometric part being applied by the shader at run time.
   */
  preScaleForRendering() {
    this.preScaled = true;
    this.l00.scaleInPlace(SH3ylmBasisConstants[0]);
    this.l1_1.scaleInPlace(SH3ylmBasisConstants[1]);
    this.l10.scaleInPlace(SH3ylmBasisConstants[2]);
    this.l11.scaleInPlace(SH3ylmBasisConstants[3]);
    this.l2_2.scaleInPlace(SH3ylmBasisConstants[4]);
    this.l2_1.scaleInPlace(SH3ylmBasisConstants[5]);
    this.l20.scaleInPlace(SH3ylmBasisConstants[6]);
    this.l21.scaleInPlace(SH3ylmBasisConstants[7]);
    this.l22.scaleInPlace(SH3ylmBasisConstants[8]);
  }
  /**
   * update the spherical harmonics coefficients from the given array
   * @param data defines the 9x3 coefficients (l00, l1-1, l10, l11, l2-2, l2-1, l20, l21, l22)
   * @returns the spherical harmonics (this)
   */
  updateFromArray(data) {
    Vector3.FromArrayToRef(data[0], 0, this.l00);
    Vector3.FromArrayToRef(data[1], 0, this.l1_1);
    Vector3.FromArrayToRef(data[2], 0, this.l10);
    Vector3.FromArrayToRef(data[3], 0, this.l11);
    Vector3.FromArrayToRef(data[4], 0, this.l2_2);
    Vector3.FromArrayToRef(data[5], 0, this.l2_1);
    Vector3.FromArrayToRef(data[6], 0, this.l20);
    Vector3.FromArrayToRef(data[7], 0, this.l21);
    Vector3.FromArrayToRef(data[8], 0, this.l22);
    return this;
  }
  /**
   * update the spherical harmonics coefficients from the given floats array
   * @param data defines the 9x3 coefficients (l00, l1-1, l10, l11, l2-2, l2-1, l20, l21, l22)
   * @returns the spherical harmonics (this)
   */
  updateFromFloatsArray(data) {
    Vector3.FromFloatsToRef(data[0], data[1], data[2], this.l00);
    Vector3.FromFloatsToRef(data[3], data[4], data[5], this.l1_1);
    Vector3.FromFloatsToRef(data[6], data[7], data[8], this.l10);
    Vector3.FromFloatsToRef(data[9], data[10], data[11], this.l11);
    Vector3.FromFloatsToRef(data[12], data[13], data[14], this.l2_2);
    Vector3.FromFloatsToRef(data[15], data[16], data[17], this.l2_1);
    Vector3.FromFloatsToRef(data[18], data[19], data[20], this.l20);
    Vector3.FromFloatsToRef(data[21], data[22], data[23], this.l21);
    Vector3.FromFloatsToRef(data[24], data[25], data[26], this.l22);
    return this;
  }
  /**
   * Constructs a spherical harmonics from an array.
   * @param data defines the 9x3 coefficients (l00, l1-1, l10, l11, l2-2, l2-1, l20, l21, l22)
   * @returns the spherical harmonics
   */
  static FromArray(data) {
    const sh = new _SphericalHarmonics();
    return sh.updateFromArray(data);
  }
  // Keep for references.
  /**
   * Gets the spherical harmonics from polynomial
   * @param polynomial the spherical polynomial
   * @returns the spherical harmonics
   */
  static FromPolynomial(polynomial) {
    const result = new _SphericalHarmonics();
    result.l00 = polynomial.xx.scale(0.376127).add(polynomial.yy.scale(0.376127)).add(polynomial.zz.scale(0.376126));
    result.l1_1 = polynomial.y.scale(0.977204);
    result.l10 = polynomial.z.scale(0.977204);
    result.l11 = polynomial.x.scale(0.977204);
    result.l2_2 = polynomial.xy.scale(1.16538);
    result.l2_1 = polynomial.yz.scale(1.16538);
    result.l20 = polynomial.zz.scale(1.34567).subtract(polynomial.xx.scale(0.672834)).subtract(polynomial.yy.scale(0.672834));
    result.l21 = polynomial.zx.scale(1.16538);
    result.l22 = polynomial.xx.scale(1.16538).subtract(polynomial.yy.scale(1.16538));
    result.l1_1.scaleInPlace(-1);
    result.l11.scaleInPlace(-1);
    result.l2_1.scaleInPlace(-1);
    result.l21.scaleInPlace(-1);
    result.scaleInPlace(Math.PI);
    return result;
  }
};
var SphericalPolynomial = class _SphericalPolynomial {
  constructor() {
    this.x = Vector3.Zero();
    this.y = Vector3.Zero();
    this.z = Vector3.Zero();
    this.xx = Vector3.Zero();
    this.yy = Vector3.Zero();
    this.zz = Vector3.Zero();
    this.xy = Vector3.Zero();
    this.yz = Vector3.Zero();
    this.zx = Vector3.Zero();
  }
  /**
   * The spherical harmonics used to create the polynomials.
   */
  get preScaledHarmonics() {
    if (!this._harmonics) {
      this._harmonics = SphericalHarmonics.FromPolynomial(this);
    }
    if (!this._harmonics.preScaled) {
      this._harmonics.preScaleForRendering();
    }
    return this._harmonics;
  }
  /**
   * Adds an ambient color to the spherical polynomial
   * @param color the color to add
   */
  addAmbient(color) {
    TmpVectors.Vector3[0].copyFromFloats(color.r, color.g, color.b);
    const colorVector = TmpVectors.Vector3[0];
    this.xx.addInPlace(colorVector);
    this.yy.addInPlace(colorVector);
    this.zz.addInPlace(colorVector);
  }
  /**
   * Scales the spherical polynomial by the given amount
   * @param scale the amount to scale
   */
  scaleInPlace(scale) {
    this.x.scaleInPlace(scale);
    this.y.scaleInPlace(scale);
    this.z.scaleInPlace(scale);
    this.xx.scaleInPlace(scale);
    this.yy.scaleInPlace(scale);
    this.zz.scaleInPlace(scale);
    this.yz.scaleInPlace(scale);
    this.zx.scaleInPlace(scale);
    this.xy.scaleInPlace(scale);
  }
  /**
   * Updates the spherical polynomial from harmonics
   * @param harmonics the spherical harmonics
   * @returns the spherical polynomial
   */
  updateFromHarmonics(harmonics) {
    this._harmonics = harmonics;
    this.x.copyFrom(harmonics.l11);
    this.x.scaleInPlace(1.02333).scaleInPlace(-1);
    this.y.copyFrom(harmonics.l1_1);
    this.y.scaleInPlace(1.02333).scaleInPlace(-1);
    this.z.copyFrom(harmonics.l10);
    this.z.scaleInPlace(1.02333);
    this.xx.copyFrom(harmonics.l00);
    TmpVectors.Vector3[0].copyFrom(harmonics.l20).scaleInPlace(0.247708);
    TmpVectors.Vector3[1].copyFrom(harmonics.l22).scaleInPlace(0.429043);
    this.xx.scaleInPlace(0.886277).subtractInPlace(TmpVectors.Vector3[0]).addInPlace(TmpVectors.Vector3[1]);
    this.yy.copyFrom(harmonics.l00);
    this.yy.scaleInPlace(0.886277).subtractInPlace(TmpVectors.Vector3[0]).subtractInPlace(TmpVectors.Vector3[1]);
    this.zz.copyFrom(harmonics.l00);
    TmpVectors.Vector3[0].copyFrom(harmonics.l20).scaleInPlace(0.495417);
    this.zz.scaleInPlace(0.886277).addInPlace(TmpVectors.Vector3[0]);
    this.yz.copyFrom(harmonics.l2_1);
    this.yz.scaleInPlace(0.858086).scaleInPlace(-1);
    this.zx.copyFrom(harmonics.l21);
    this.zx.scaleInPlace(0.858086).scaleInPlace(-1);
    this.xy.copyFrom(harmonics.l2_2);
    this.xy.scaleInPlace(0.858086);
    this.scaleInPlace(1 / Math.PI);
    return this;
  }
  /**
   * Gets the spherical polynomial from harmonics
   * @param harmonics the spherical harmonics
   * @returns the spherical polynomial
   */
  static FromHarmonics(harmonics) {
    const result = new _SphericalPolynomial();
    return result.updateFromHarmonics(harmonics);
  }
  /**
   * Constructs a spherical polynomial from an array.
   * @param data defines the 9x3 coefficients (x, y, z, xx, yy, zz, yz, zx, xy)
   * @returns the spherical polynomial
   */
  static FromArray(data) {
    const sp = new _SphericalPolynomial();
    Vector3.FromArrayToRef(data[0], 0, sp.x);
    Vector3.FromArrayToRef(data[1], 0, sp.y);
    Vector3.FromArrayToRef(data[2], 0, sp.z);
    Vector3.FromArrayToRef(data[3], 0, sp.xx);
    Vector3.FromArrayToRef(data[4], 0, sp.yy);
    Vector3.FromArrayToRef(data[5], 0, sp.zz);
    Vector3.FromArrayToRef(data[6], 0, sp.yz);
    Vector3.FromArrayToRef(data[7], 0, sp.zx);
    Vector3.FromArrayToRef(data[8], 0, sp.xy);
    return sp;
  }
};

// node_modules/@babylonjs/core/Misc/HighDynamicRange/cubemapToSphericalPolynomial.js
var FileFaceOrientation = class {
  constructor(name, worldAxisForNormal, worldAxisForFileX, worldAxisForFileY) {
    this.name = name;
    this.worldAxisForNormal = worldAxisForNormal;
    this.worldAxisForFileX = worldAxisForFileX;
    this.worldAxisForFileY = worldAxisForFileY;
  }
};
var CubeMapToSphericalPolynomialTools = class {
  /**
   * Converts a texture to the according Spherical Polynomial data.
   * This extracts the first 3 orders only as they are the only one used in the lighting.
   *
   * @param texture The texture to extract the information from.
   * @returns The Spherical Polynomial data.
   */
  static ConvertCubeMapTextureToSphericalPolynomial(texture) {
    var _a;
    if (!texture.isCube) {
      return null;
    }
    (_a = texture.getScene()) == null ? void 0 : _a.getEngine().flushFramebuffer();
    const size = texture.getSize().width;
    const rightPromise = texture.readPixels(0, void 0, void 0, false);
    const leftPromise = texture.readPixels(1, void 0, void 0, false);
    let upPromise;
    let downPromise;
    if (texture.isRenderTarget) {
      upPromise = texture.readPixels(3, void 0, void 0, false);
      downPromise = texture.readPixels(2, void 0, void 0, false);
    } else {
      upPromise = texture.readPixels(2, void 0, void 0, false);
      downPromise = texture.readPixels(3, void 0, void 0, false);
    }
    const frontPromise = texture.readPixels(4, void 0, void 0, false);
    const backPromise = texture.readPixels(5, void 0, void 0, false);
    const gammaSpace = texture.gammaSpace;
    const format = 5;
    let type = 0;
    if (texture.textureType == 1 || texture.textureType == 2) {
      type = 1;
    }
    return new Promise((resolve) => {
      Promise.all([leftPromise, rightPromise, upPromise, downPromise, frontPromise, backPromise]).then(([left, right, up, down, front, back]) => {
        const cubeInfo = {
          size,
          right,
          left,
          up,
          down,
          front,
          back,
          format,
          type,
          gammaSpace
        };
        resolve(this.ConvertCubeMapToSphericalPolynomial(cubeInfo));
      });
    });
  }
  /**
   * Compute the area on the unit sphere of the rectangle defined by (x,y) and the origin
   * See https://www.rorydriscoll.com/2012/01/15/cubemap-texel-solid-angle/
   * @param x
   * @param y
   * @returns the area
   */
  static _AreaElement(x, y) {
    return Math.atan2(x * y, Math.sqrt(x * x + y * y + 1));
  }
  /**
   * Converts a cubemap to the according Spherical Polynomial data.
   * This extracts the first 3 orders only as they are the only one used in the lighting.
   *
   * @param cubeInfo The Cube map to extract the information from.
   * @returns The Spherical Polynomial data.
   */
  static ConvertCubeMapToSphericalPolynomial(cubeInfo) {
    const sphericalHarmonics = new SphericalHarmonics();
    let totalSolidAngle = 0;
    const du = 2 / cubeInfo.size;
    const dv = du;
    const halfTexel = 0.5 * du;
    const minUV = halfTexel - 1;
    for (let faceIndex = 0; faceIndex < 6; faceIndex++) {
      const fileFace = this._FileFaces[faceIndex];
      const dataArray = cubeInfo[fileFace.name];
      let v = minUV;
      const stride = cubeInfo.format === 5 ? 4 : 3;
      for (let y = 0; y < cubeInfo.size; y++) {
        let u = minUV;
        for (let x = 0; x < cubeInfo.size; x++) {
          const worldDirection = fileFace.worldAxisForFileX.scale(u).add(fileFace.worldAxisForFileY.scale(v)).add(fileFace.worldAxisForNormal);
          worldDirection.normalize();
          const deltaSolidAngle = this._AreaElement(u - halfTexel, v - halfTexel) - this._AreaElement(u - halfTexel, v + halfTexel) - this._AreaElement(u + halfTexel, v - halfTexel) + this._AreaElement(u + halfTexel, v + halfTexel);
          let r = dataArray[y * cubeInfo.size * stride + x * stride + 0];
          let g = dataArray[y * cubeInfo.size * stride + x * stride + 1];
          let b = dataArray[y * cubeInfo.size * stride + x * stride + 2];
          if (isNaN(r)) {
            r = 0;
          }
          if (isNaN(g)) {
            g = 0;
          }
          if (isNaN(b)) {
            b = 0;
          }
          if (cubeInfo.type === 0) {
            r /= 255;
            g /= 255;
            b /= 255;
          }
          if (cubeInfo.gammaSpace) {
            r = Math.pow(Clamp(r), ToLinearSpace);
            g = Math.pow(Clamp(g), ToLinearSpace);
            b = Math.pow(Clamp(b), ToLinearSpace);
          }
          const max = this.MAX_HDRI_VALUE;
          if (this.PRESERVE_CLAMPED_COLORS) {
            const currentMax = Math.max(r, g, b);
            if (currentMax > max) {
              const factor = max / currentMax;
              r *= factor;
              g *= factor;
              b *= factor;
            }
          } else {
            r = Clamp(r, 0, max);
            g = Clamp(g, 0, max);
            b = Clamp(b, 0, max);
          }
          const color = new Color3(r, g, b);
          sphericalHarmonics.addLight(worldDirection, color, deltaSolidAngle);
          totalSolidAngle += deltaSolidAngle;
          u += du;
        }
        v += dv;
      }
    }
    const sphereSolidAngle = 4 * Math.PI;
    const facesProcessed = 6;
    const expectedSolidAngle = sphereSolidAngle * facesProcessed / 6;
    const correctionFactor = expectedSolidAngle / totalSolidAngle;
    sphericalHarmonics.scaleInPlace(correctionFactor);
    sphericalHarmonics.convertIncidentRadianceToIrradiance();
    sphericalHarmonics.convertIrradianceToLambertianRadiance();
    return SphericalPolynomial.FromHarmonics(sphericalHarmonics);
  }
};
CubeMapToSphericalPolynomialTools._FileFaces = [
  new FileFaceOrientation("right", new Vector3(1, 0, 0), new Vector3(0, 0, -1), new Vector3(0, -1, 0)),
  new FileFaceOrientation("left", new Vector3(-1, 0, 0), new Vector3(0, 0, 1), new Vector3(0, -1, 0)),
  new FileFaceOrientation("up", new Vector3(0, 1, 0), new Vector3(1, 0, 0), new Vector3(0, 0, 1)),
  new FileFaceOrientation("down", new Vector3(0, -1, 0), new Vector3(1, 0, 0), new Vector3(0, 0, -1)),
  new FileFaceOrientation("front", new Vector3(0, 0, 1), new Vector3(1, 0, 0), new Vector3(0, -1, 0)),
  new FileFaceOrientation("back", new Vector3(0, 0, -1), new Vector3(-1, 0, 0), new Vector3(0, -1, 0))
  // -Z bottom
];
CubeMapToSphericalPolynomialTools.MAX_HDRI_VALUE = 4096;
CubeMapToSphericalPolynomialTools.PRESERVE_CLAMPED_COLORS = false;

// node_modules/@babylonjs/core/PostProcesses/postProcess.js
AbstractEngine.prototype.setTextureFromPostProcess = function(channel, postProcess, name) {
  let postProcessInput = null;
  if (postProcess) {
    if (postProcess._forcedOutputTexture) {
      postProcessInput = postProcess._forcedOutputTexture;
    } else if (postProcess._textures.data[postProcess._currentRenderTextureInd]) {
      postProcessInput = postProcess._textures.data[postProcess._currentRenderTextureInd];
    }
  }
  this._bindTexture(channel, (postProcessInput == null ? void 0 : postProcessInput.texture) ?? null, name);
};
AbstractEngine.prototype.setTextureFromPostProcessOutput = function(channel, postProcess, name) {
  var _a;
  this._bindTexture(channel, ((_a = postProcess == null ? void 0 : postProcess._outputTexture) == null ? void 0 : _a.texture) ?? null, name);
};
Effect.prototype.setTextureFromPostProcess = function(channel, postProcess) {
  this._engine.setTextureFromPostProcess(this._samplers[channel], postProcess, channel);
};
Effect.prototype.setTextureFromPostProcessOutput = function(channel, postProcess) {
  this._engine.setTextureFromPostProcessOutput(this._samplers[channel], postProcess, channel);
};
var PostProcess = class _PostProcess {
  /**
   * Registers a shader code processing with a post process name.
   * @param postProcessName name of the post process. Use null for the fallback shader code processing. This is the shader code processing that will be used in case no specific shader code processing has been associated to a post process name
   * @param customShaderCodeProcessing shader code processing to associate to the post process name
   */
  static RegisterShaderCodeProcessing(postProcessName, customShaderCodeProcessing) {
    if (!customShaderCodeProcessing) {
      delete _PostProcess._CustomShaderCodeProcessing[postProcessName ?? ""];
      return;
    }
    _PostProcess._CustomShaderCodeProcessing[postProcessName ?? ""] = customShaderCodeProcessing;
  }
  static _GetShaderCodeProcessing(postProcessName) {
    return _PostProcess._CustomShaderCodeProcessing[postProcessName] ?? _PostProcess._CustomShaderCodeProcessing[""];
  }
  /**
   * Number of sample textures (default: 1)
   */
  get samples() {
    return this._samples;
  }
  set samples(n) {
    this._samples = Math.min(n, this._engine.getCaps().maxMSAASamples);
    this._textures.forEach((texture) => {
      texture.setSamples(this._samples);
    });
  }
  /**
   * Gets the shader language type used to generate vertex and fragment source code.
   */
  get shaderLanguage() {
    return this._shaderLanguage;
  }
  /**
   * Returns the fragment url or shader name used in the post process.
   * @returns the fragment url or name in the shader store.
   */
  getEffectName() {
    return this._fragmentUrl;
  }
  /**
   * A function that is added to the onActivateObservable
   */
  set onActivate(callback) {
    if (this._onActivateObserver) {
      this.onActivateObservable.remove(this._onActivateObserver);
    }
    if (callback) {
      this._onActivateObserver = this.onActivateObservable.add(callback);
    }
  }
  /**
   * A function that is added to the onSizeChangedObservable
   */
  set onSizeChanged(callback) {
    if (this._onSizeChangedObserver) {
      this.onSizeChangedObservable.remove(this._onSizeChangedObserver);
    }
    this._onSizeChangedObserver = this.onSizeChangedObservable.add(callback);
  }
  /**
   * A function that is added to the onApplyObservable
   */
  set onApply(callback) {
    if (this._onApplyObserver) {
      this.onApplyObservable.remove(this._onApplyObserver);
    }
    this._onApplyObserver = this.onApplyObservable.add(callback);
  }
  /**
   * A function that is added to the onBeforeRenderObservable
   */
  set onBeforeRender(callback) {
    if (this._onBeforeRenderObserver) {
      this.onBeforeRenderObservable.remove(this._onBeforeRenderObserver);
    }
    this._onBeforeRenderObserver = this.onBeforeRenderObservable.add(callback);
  }
  /**
   * A function that is added to the onAfterRenderObservable
   */
  set onAfterRender(callback) {
    if (this._onAfterRenderObserver) {
      this.onAfterRenderObservable.remove(this._onAfterRenderObserver);
    }
    this._onAfterRenderObserver = this.onAfterRenderObservable.add(callback);
  }
  /**
   * The input texture for this post process and the output texture of the previous post process. When added to a pipeline the previous post process will
   * render it's output into this texture and this texture will be used as textureSampler in the fragment shader of this post process.
   */
  get inputTexture() {
    return this._textures.data[this._currentRenderTextureInd];
  }
  set inputTexture(value) {
    this._forcedOutputTexture = value;
  }
  /**
   * Since inputTexture should always be defined, if we previously manually set `inputTexture`,
   * the only way to unset it is to use this function to restore its internal state
   */
  restoreDefaultInputTexture() {
    if (this._forcedOutputTexture) {
      this._forcedOutputTexture = null;
      this.markTextureDirty();
    }
  }
  /**
   * Gets the camera which post process is applied to.
   * @returns The camera the post process is applied to.
   */
  getCamera() {
    return this._camera;
  }
  /**
   * Gets the texel size of the postprocess.
   * See https://en.wikipedia.org/wiki/Texel_(graphics)
   */
  get texelSize() {
    if (this._shareOutputWithPostProcess) {
      return this._shareOutputWithPostProcess.texelSize;
    }
    if (this._forcedOutputTexture) {
      this._texelSize.copyFromFloats(1 / this._forcedOutputTexture.width, 1 / this._forcedOutputTexture.height);
    }
    return this._texelSize;
  }
  /** @internal */
  constructor(name, fragmentUrl, parameters, samplers, _size, camera, samplingMode = 1, engine, reusable, defines = null, textureType = 0, vertexUrl = "postprocess", indexParameters, blockCompilation = false, textureFormat = 5, shaderLanguage, extraInitializations) {
    this._parentContainer = null;
    this.width = -1;
    this.height = -1;
    this.nodeMaterialSource = null;
    this._outputTexture = null;
    this.autoClear = true;
    this.forceAutoClearInAlphaMode = false;
    this.alphaMode = 0;
    this.animations = [];
    this.enablePixelPerfectMode = false;
    this.forceFullscreenViewport = true;
    this.scaleMode = 1;
    this.alwaysForcePOT = false;
    this._samples = 1;
    this.adaptScaleToCurrentViewport = false;
    this._shadersLoaded = false;
    this._webGPUReady = false;
    this._reusable = false;
    this._renderId = 0;
    this.externalTextureSamplerBinding = false;
    this._textures = new SmartArray(2);
    this._textureCache = [];
    this._currentRenderTextureInd = 0;
    this._scaleRatio = new Vector2(1, 1);
    this._texelSize = Vector2.Zero();
    this.onEffectCreatedObservable = new Observable(void 0, true);
    this.onActivateObservable = new Observable();
    this.onSizeChangedObservable = new Observable();
    this.onApplyObservable = new Observable();
    this.onBeforeRenderObservable = new Observable();
    this.onAfterRenderObservable = new Observable();
    this._importPromises = [];
    this.name = name;
    let size = 1;
    let uniformBuffers = null;
    if (parameters && !Array.isArray(parameters)) {
      const options = parameters;
      parameters = options.uniforms ?? null;
      samplers = options.samplers ?? null;
      size = options.size ?? 1;
      camera = options.camera ?? null;
      samplingMode = options.samplingMode ?? 1;
      engine = options.engine;
      reusable = options.reusable;
      defines = options.defines ?? null;
      textureType = options.textureType ?? 0;
      vertexUrl = options.vertexUrl ?? "postprocess";
      indexParameters = options.indexParameters;
      blockCompilation = options.blockCompilation ?? false;
      textureFormat = options.textureFormat ?? 5;
      shaderLanguage = options.shaderLanguage ?? 0;
      uniformBuffers = options.uniformBuffers ?? null;
      extraInitializations = options.extraInitializations;
    } else if (_size) {
      if (typeof _size === "number") {
        size = _size;
      } else {
        size = { width: _size.width, height: _size.height };
      }
    }
    if (camera != null) {
      this._camera = camera;
      this._scene = camera.getScene();
      camera.attachPostProcess(this);
      this._engine = this._scene.getEngine();
      this._scene.postProcesses.push(this);
      this.uniqueId = this._scene.getUniqueId();
    } else if (engine) {
      this._engine = engine;
      this._engine.postProcesses.push(this);
    }
    this._options = size;
    this.renderTargetSamplingMode = samplingMode ? samplingMode : 1;
    this._reusable = reusable || false;
    this._textureType = textureType;
    this._textureFormat = textureFormat;
    this._shaderLanguage = shaderLanguage || 0;
    this._samplers = samplers || [];
    this._samplers.push("textureSampler");
    this._fragmentUrl = fragmentUrl;
    this._vertexUrl = vertexUrl;
    this._parameters = parameters || [];
    this._parameters.push("scale");
    this._uniformBuffers = uniformBuffers || [];
    this._indexParameters = indexParameters;
    this._drawWrapper = new DrawWrapper(this._engine);
    this._webGPUReady = this._shaderLanguage === 1;
    this._postConstructor(blockCompilation, defines, extraInitializations);
  }
  /** @internal */
  _gatherImports(useWebGPU = false, list) {
    if (useWebGPU && this._webGPUReady) {
      list.push(Promise.all([import("./postprocess.vertex-S2R34F5F.js")]));
    } else {
      list.push(Promise.all([import("./postprocess.vertex-CXCXIKDA.js")]));
    }
  }
  _postConstructor(blockCompilation, defines = null, extraInitializations) {
    const engine = this.getEngine();
    const useWebGPU = engine.isWebGPU && !_PostProcess.ForceGLSL;
    this._gatherImports(useWebGPU, this._importPromises);
    if (extraInitializations) {
      extraInitializations(useWebGPU, this._importPromises);
    }
    if (useWebGPU && this._webGPUReady) {
      this._shaderLanguage = 1;
    }
    if (!blockCompilation) {
      this.updateEffect(defines);
    }
  }
  /**
   * Gets a string identifying the name of the class
   * @returns "PostProcess" string
   */
  getClassName() {
    return "PostProcess";
  }
  /**
   * Gets the engine which this post process belongs to.
   * @returns The engine the post process was enabled with.
   */
  getEngine() {
    return this._engine;
  }
  /**
   * The effect that is created when initializing the post process.
   * @returns The created effect corresponding the postprocess.
   */
  getEffect() {
    return this._drawWrapper.effect;
  }
  /**
   * To avoid multiple redundant textures for multiple post process, the output the output texture for this post process can be shared with another.
   * @param postProcess The post process to share the output with.
   * @returns This post process.
   */
  shareOutputWith(postProcess) {
    this._disposeTextures();
    this._shareOutputWithPostProcess = postProcess;
    return this;
  }
  /**
   * Reverses the effect of calling shareOutputWith and returns the post process back to its original state.
   * This should be called if the post process that shares output with this post process is disabled/disposed.
   */
  useOwnOutput() {
    if (this._textures.length == 0) {
      this._textures = new SmartArray(2);
    }
    this._shareOutputWithPostProcess = null;
  }
  /**
   * Updates the effect with the current post process compile time values and recompiles the shader.
   * @param defines Define statements that should be added at the beginning of the shader. (default: null)
   * @param uniforms Set of uniform variables that will be passed to the shader. (default: null)
   * @param samplers Set of Texture2D variables that will be passed to the shader. (default: null)
   * @param indexParameters The index parameters to be used for babylons include syntax "#include<kernelBlurVaryingDeclaration>[0..varyingCount]". (default: undefined) See usage in babylon.blurPostProcess.ts and kernelBlur.vertex.fx
   * @param onCompiled Called when the shader has been compiled.
   * @param onError Called if there is an error when compiling a shader.
   * @param vertexUrl The url of the vertex shader to be used (default: the one given at construction time)
   * @param fragmentUrl The url of the fragment shader to be used (default: the one given at construction time)
   */
  updateEffect(defines = null, uniforms = null, samplers = null, indexParameters, onCompiled, onError, vertexUrl, fragmentUrl) {
    const customShaderCodeProcessing = _PostProcess._GetShaderCodeProcessing(this.name);
    if (customShaderCodeProcessing == null ? void 0 : customShaderCodeProcessing.defineCustomBindings) {
      const newUniforms = (uniforms == null ? void 0 : uniforms.slice()) ?? [];
      newUniforms.push(...this._parameters);
      const newSamplers = (samplers == null ? void 0 : samplers.slice()) ?? [];
      newSamplers.push(...this._samplers);
      defines = customShaderCodeProcessing.defineCustomBindings(this.name, defines, newUniforms, newSamplers);
      uniforms = newUniforms;
      samplers = newSamplers;
    }
    this._postProcessDefines = defines;
    this._drawWrapper.effect = this._engine.createEffect({ vertex: vertexUrl ?? this._vertexUrl, fragment: fragmentUrl ?? this._fragmentUrl }, {
      attributes: ["position"],
      uniformsNames: uniforms || this._parameters,
      uniformBuffersNames: this._uniformBuffers,
      samplers: samplers || this._samplers,
      defines: defines !== null ? defines : "",
      fallbacks: null,
      onCompiled: onCompiled ?? null,
      onError: onError ?? null,
      indexParameters: indexParameters || this._indexParameters,
      processCodeAfterIncludes: (customShaderCodeProcessing == null ? void 0 : customShaderCodeProcessing.processCodeAfterIncludes) ? (shaderType, code) => customShaderCodeProcessing.processCodeAfterIncludes(this.name, shaderType, code) : null,
      processFinalCode: (customShaderCodeProcessing == null ? void 0 : customShaderCodeProcessing.processFinalCode) ? (shaderType, code) => customShaderCodeProcessing.processFinalCode(this.name, shaderType, code) : null,
      shaderLanguage: this._shaderLanguage,
      extraInitializationsAsync: this._shadersLoaded ? void 0 : async () => {
        await Promise.all(this._importPromises);
        this._shadersLoaded = true;
      }
    }, this._engine);
    this.onEffectCreatedObservable.notifyObservers(this._drawWrapper.effect);
  }
  /**
   * The post process is reusable if it can be used multiple times within one frame.
   * @returns If the post process is reusable
   */
  isReusable() {
    return this._reusable;
  }
  /** invalidate frameBuffer to hint the postprocess to create a depth buffer */
  markTextureDirty() {
    this.width = -1;
  }
  _createRenderTargetTexture(textureSize, textureOptions, channel = 0) {
    for (let i = 0; i < this._textureCache.length; i++) {
      if (this._textureCache[i].texture.width === textureSize.width && this._textureCache[i].texture.height === textureSize.height && this._textureCache[i].postProcessChannel === channel && this._textureCache[i].texture._generateDepthBuffer === textureOptions.generateDepthBuffer && this._textureCache[i].texture.samples === textureOptions.samples) {
        return this._textureCache[i].texture;
      }
    }
    const tex = this._engine.createRenderTargetTexture(textureSize, textureOptions);
    this._textureCache.push({ texture: tex, postProcessChannel: channel, lastUsedRenderId: -1 });
    return tex;
  }
  _flushTextureCache() {
    const currentRenderId = this._renderId;
    for (let i = this._textureCache.length - 1; i >= 0; i--) {
      if (currentRenderId - this._textureCache[i].lastUsedRenderId > 100) {
        let currentlyUsed = false;
        for (let j = 0; j < this._textures.length; j++) {
          if (this._textures.data[j] === this._textureCache[i].texture) {
            currentlyUsed = true;
            break;
          }
        }
        if (!currentlyUsed) {
          this._textureCache[i].texture.dispose();
          this._textureCache.splice(i, 1);
        }
      }
    }
  }
  /**
   * Resizes the post-process texture
   * @param width Width of the texture
   * @param height Height of the texture
   * @param camera The camera this post-process is applied to. Pass null if the post-process is used outside the context of a camera post-process chain (default: null)
   * @param needMipMaps True if mip maps need to be generated after render (default: false)
   * @param forceDepthStencil True to force post-process texture creation with stencil depth and buffer (default: false)
   */
  resize(width, height, camera = null, needMipMaps = false, forceDepthStencil = false) {
    if (this._textures.length > 0) {
      this._textures.reset();
    }
    this.width = width;
    this.height = height;
    let firstPP = null;
    if (camera) {
      for (let i = 0; i < camera._postProcesses.length; i++) {
        if (camera._postProcesses[i] !== null) {
          firstPP = camera._postProcesses[i];
          break;
        }
      }
    }
    const textureSize = { width: this.width, height: this.height };
    const textureOptions = {
      generateMipMaps: needMipMaps,
      generateDepthBuffer: forceDepthStencil || firstPP === this,
      generateStencilBuffer: (forceDepthStencil || firstPP === this) && this._engine.isStencilEnable,
      samplingMode: this.renderTargetSamplingMode,
      type: this._textureType,
      format: this._textureFormat,
      samples: this._samples,
      label: "PostProcessRTT-" + this.name
    };
    this._textures.push(this._createRenderTargetTexture(textureSize, textureOptions, 0));
    if (this._reusable) {
      this._textures.push(this._createRenderTargetTexture(textureSize, textureOptions, 1));
    }
    this._texelSize.copyFromFloats(1 / this.width, 1 / this.height);
    this.onSizeChangedObservable.notifyObservers(this);
  }
  _getTarget() {
    let target;
    if (this._shareOutputWithPostProcess) {
      target = this._shareOutputWithPostProcess.inputTexture;
    } else if (this._forcedOutputTexture) {
      target = this._forcedOutputTexture;
      this.width = this._forcedOutputTexture.width;
      this.height = this._forcedOutputTexture.height;
    } else {
      target = this.inputTexture;
      let cache;
      for (let i = 0; i < this._textureCache.length; i++) {
        if (this._textureCache[i].texture === target) {
          cache = this._textureCache[i];
          break;
        }
      }
      if (cache) {
        cache.lastUsedRenderId = this._renderId;
      }
    }
    return target;
  }
  /**
   * Activates the post process by intializing the textures to be used when executed. Notifies onActivateObservable.
   * When this post process is used in a pipeline, this is call will bind the input texture of this post process to the output of the previous.
   * @param camera The camera that will be used in the post process. This camera will be used when calling onActivateObservable.
   * @param sourceTexture The source texture to be inspected to get the width and height if not specified in the post process constructor. (default: null)
   * @param forceDepthStencil If true, a depth and stencil buffer will be generated. (default: false)
   * @returns The render target wrapper that was bound to be written to.
   */
  activate(camera, sourceTexture = null, forceDepthStencil) {
    var _a, _b;
    camera = camera || this._camera;
    const scene = camera.getScene();
    const engine = scene.getEngine();
    const maxSize = engine.getCaps().maxTextureSize;
    const requiredWidth = (sourceTexture ? sourceTexture.width : this._engine.getRenderWidth(true)) * this._options | 0;
    const requiredHeight = (sourceTexture ? sourceTexture.height : this._engine.getRenderHeight(true)) * this._options | 0;
    let desiredWidth = this._options.width || requiredWidth;
    let desiredHeight = this._options.height || requiredHeight;
    const needMipMaps = this.renderTargetSamplingMode !== 7 && this.renderTargetSamplingMode !== 1 && this.renderTargetSamplingMode !== 2;
    let target = null;
    if (!this._shareOutputWithPostProcess && !this._forcedOutputTexture) {
      if (this.adaptScaleToCurrentViewport) {
        const currentViewport = engine.currentViewport;
        if (currentViewport) {
          desiredWidth *= currentViewport.width;
          desiredHeight *= currentViewport.height;
        }
      }
      if (needMipMaps || this.alwaysForcePOT) {
        if (!this._options.width) {
          desiredWidth = engine.needPOTTextures ? GetExponentOfTwo(desiredWidth, maxSize, this.scaleMode) : desiredWidth;
        }
        if (!this._options.height) {
          desiredHeight = engine.needPOTTextures ? GetExponentOfTwo(desiredHeight, maxSize, this.scaleMode) : desiredHeight;
        }
      }
      if (this.width !== desiredWidth || this.height !== desiredHeight || !(target = this._getTarget())) {
        this.resize(desiredWidth, desiredHeight, camera, needMipMaps, forceDepthStencil);
      }
      this._textures.forEach((texture) => {
        if (texture.samples !== this.samples) {
          this._engine.updateRenderTargetTextureSampleCount(texture, this.samples);
        }
      });
      this._flushTextureCache();
      this._renderId++;
    }
    if (!target) {
      target = this._getTarget();
    }
    if (this.enablePixelPerfectMode) {
      this._scaleRatio.copyFromFloats(requiredWidth / desiredWidth, requiredHeight / desiredHeight);
      this._engine.bindFramebuffer(target, 0, requiredWidth, requiredHeight, this.forceFullscreenViewport);
    } else {
      this._scaleRatio.copyFromFloats(1, 1);
      this._engine.bindFramebuffer(target, 0, void 0, void 0, this.forceFullscreenViewport);
    }
    (_b = (_a = this._engine)._debugInsertMarker) == null ? void 0 : _b.call(_a, `post process ${this.name} input`);
    this.onActivateObservable.notifyObservers(camera);
    if (this.autoClear && (this.alphaMode === 0 || this.forceAutoClearInAlphaMode)) {
      this._engine.clear(this.clearColor ? this.clearColor : scene.clearColor, scene._allowPostProcessClearColor, true, true);
    }
    if (this._reusable) {
      this._currentRenderTextureInd = (this._currentRenderTextureInd + 1) % 2;
    }
    return target;
  }
  /**
   * If the post process is supported.
   */
  get isSupported() {
    return this._drawWrapper.effect.isSupported;
  }
  /**
   * The aspect ratio of the output texture.
   */
  get aspectRatio() {
    if (this._shareOutputWithPostProcess) {
      return this._shareOutputWithPostProcess.aspectRatio;
    }
    if (this._forcedOutputTexture) {
      return this._forcedOutputTexture.width / this._forcedOutputTexture.height;
    }
    return this.width / this.height;
  }
  /**
   * Get a value indicating if the post-process is ready to be used
   * @returns true if the post-process is ready (shader is compiled)
   */
  isReady() {
    var _a;
    return ((_a = this._drawWrapper.effect) == null ? void 0 : _a.isReady()) ?? false;
  }
  /**
   * Binds all textures and uniforms to the shader, this will be run on every pass.
   * @returns the effect corresponding to this post process. Null if not compiled or not ready.
   */
  apply() {
    var _a, _b, _c;
    if (!((_a = this._drawWrapper.effect) == null ? void 0 : _a.isReady())) {
      return null;
    }
    this._engine.enableEffect(this._drawWrapper);
    this._engine.setState(false);
    this._engine.setDepthBuffer(false);
    this._engine.setDepthWrite(false);
    this._engine.setAlphaMode(this.alphaMode);
    if (this.alphaConstants) {
      this.getEngine().setAlphaConstants(this.alphaConstants.r, this.alphaConstants.g, this.alphaConstants.b, this.alphaConstants.a);
    }
    let source;
    if (this._shareOutputWithPostProcess) {
      source = this._shareOutputWithPostProcess.inputTexture;
    } else if (this._forcedOutputTexture) {
      source = this._forcedOutputTexture;
    } else {
      source = this.inputTexture;
    }
    if (!this.externalTextureSamplerBinding) {
      this._drawWrapper.effect._bindTexture("textureSampler", source == null ? void 0 : source.texture);
    }
    this._drawWrapper.effect.setVector2("scale", this._scaleRatio);
    this.onApplyObservable.notifyObservers(this._drawWrapper.effect);
    (_c = (_b = _PostProcess._GetShaderCodeProcessing(this.name)) == null ? void 0 : _b.bindCustomBindings) == null ? void 0 : _c.call(_b, this.name, this._drawWrapper.effect);
    return this._drawWrapper.effect;
  }
  _disposeTextures() {
    if (this._shareOutputWithPostProcess || this._forcedOutputTexture) {
      this._disposeTextureCache();
      return;
    }
    this._disposeTextureCache();
    this._textures.dispose();
  }
  _disposeTextureCache() {
    for (let i = this._textureCache.length - 1; i >= 0; i--) {
      this._textureCache[i].texture.dispose();
    }
    this._textureCache.length = 0;
  }
  /**
   * Sets the required values to the prepass renderer.
   * @param prePassRenderer defines the prepass renderer to setup.
   * @returns true if the pre pass is needed.
   */
  setPrePassRenderer(prePassRenderer) {
    if (this._prePassEffectConfiguration) {
      this._prePassEffectConfiguration = prePassRenderer.addEffectConfiguration(this._prePassEffectConfiguration);
      this._prePassEffectConfiguration.enabled = true;
      return true;
    }
    return false;
  }
  /**
   * Disposes the post process.
   * @param camera The camera to dispose the post process on.
   */
  dispose(camera) {
    camera = camera || this._camera;
    this._disposeTextures();
    let index;
    if (this._scene) {
      index = this._scene.postProcesses.indexOf(this);
      if (index !== -1) {
        this._scene.postProcesses.splice(index, 1);
      }
    }
    if (this._parentContainer) {
      const index2 = this._parentContainer.postProcesses.indexOf(this);
      if (index2 > -1) {
        this._parentContainer.postProcesses.splice(index2, 1);
      }
      this._parentContainer = null;
    }
    index = this._engine.postProcesses.indexOf(this);
    if (index !== -1) {
      this._engine.postProcesses.splice(index, 1);
    }
    if (!camera) {
      return;
    }
    camera.detachPostProcess(this);
    index = camera._postProcesses.indexOf(this);
    if (index === 0 && camera._postProcesses.length > 0) {
      const firstPostProcess = this._camera._getFirstPostProcess();
      if (firstPostProcess) {
        firstPostProcess.markTextureDirty();
      }
    }
    this.onActivateObservable.clear();
    this.onAfterRenderObservable.clear();
    this.onApplyObservable.clear();
    this.onBeforeRenderObservable.clear();
    this.onSizeChangedObservable.clear();
    this.onEffectCreatedObservable.clear();
  }
  /**
   * Serializes the post process to a JSON object
   * @returns the JSON object
   */
  serialize() {
    const serializationObject = SerializationHelper.Serialize(this);
    const camera = this.getCamera() || this._scene && this._scene.activeCamera;
    serializationObject.customType = "BABYLON." + this.getClassName();
    serializationObject.cameraId = camera ? camera.id : null;
    serializationObject.reusable = this._reusable;
    serializationObject.textureType = this._textureType;
    serializationObject.fragmentUrl = this._fragmentUrl;
    serializationObject.parameters = this._parameters;
    serializationObject.samplers = this._samplers;
    serializationObject.options = this._options;
    serializationObject.defines = this._postProcessDefines;
    serializationObject.textureFormat = this._textureFormat;
    serializationObject.vertexUrl = this._vertexUrl;
    serializationObject.indexParameters = this._indexParameters;
    return serializationObject;
  }
  /**
   * Clones this post process
   * @returns a new post process similar to this one
   */
  clone() {
    const serializationObject = this.serialize();
    serializationObject._engine = this._engine;
    serializationObject.cameraId = null;
    const result = _PostProcess.Parse(serializationObject, this._scene, "");
    if (!result) {
      return null;
    }
    result.onActivateObservable = this.onActivateObservable.clone();
    result.onSizeChangedObservable = this.onSizeChangedObservable.clone();
    result.onApplyObservable = this.onApplyObservable.clone();
    result.onBeforeRenderObservable = this.onBeforeRenderObservable.clone();
    result.onAfterRenderObservable = this.onAfterRenderObservable.clone();
    result._prePassEffectConfiguration = this._prePassEffectConfiguration;
    return result;
  }
  /**
   * Creates a material from parsed material data
   * @param parsedPostProcess defines parsed post process data
   * @param scene defines the hosting scene
   * @param rootUrl defines the root URL to use to load textures
   * @returns a new post process
   */
  static Parse(parsedPostProcess, scene, rootUrl) {
    const postProcessType = GetClass(parsedPostProcess.customType);
    if (!postProcessType || !postProcessType._Parse) {
      return null;
    }
    const camera = scene ? scene.getCameraById(parsedPostProcess.cameraId) : null;
    return postProcessType._Parse(parsedPostProcess, camera, scene, rootUrl);
  }
  /**
   * @internal
   */
  static _Parse(parsedPostProcess, targetCamera, scene, rootUrl) {
    return SerializationHelper.Parse(() => {
      return new _PostProcess(parsedPostProcess.name, parsedPostProcess.fragmentUrl, parsedPostProcess.parameters, parsedPostProcess.samplers, parsedPostProcess.options, targetCamera, parsedPostProcess.renderTargetSamplingMode, parsedPostProcess._engine, parsedPostProcess.reusable, parsedPostProcess.defines, parsedPostProcess.textureType, parsedPostProcess.vertexUrl, parsedPostProcess.indexParameters, false, parsedPostProcess.textureFormat);
    }, parsedPostProcess, scene, rootUrl);
  }
};
PostProcess.ForceGLSL = false;
PostProcess._CustomShaderCodeProcessing = {};
__decorate([
  serialize()
], PostProcess.prototype, "uniqueId", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "name", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "width", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "height", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "renderTargetSamplingMode", void 0);
__decorate([
  serializeAsColor4()
], PostProcess.prototype, "clearColor", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "autoClear", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "forceAutoClearInAlphaMode", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "alphaMode", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "alphaConstants", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "enablePixelPerfectMode", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "forceFullscreenViewport", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "scaleMode", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "alwaysForcePOT", void 0);
__decorate([
  serialize("samples")
], PostProcess.prototype, "_samples", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "adaptScaleToCurrentViewport", void 0);
RegisterClass("BABYLON.PostProcess", PostProcess);

// node_modules/@babylonjs/core/Materials/Textures/renderTargetTexture.js
Effect.prototype.setDepthStencilTexture = function(channel, texture) {
  this._engine.setDepthStencilTexture(this._samplers[channel], this._uniforms[channel], texture, channel);
};
var RenderTargetTexture = class _RenderTargetTexture extends Texture {
  /**
   * Use this list to define the list of mesh you want to render.
   */
  get renderList() {
    return this._renderList;
  }
  set renderList(value) {
    if (this._unObserveRenderList) {
      this._unObserveRenderList();
      this._unObserveRenderList = null;
    }
    if (value) {
      this._unObserveRenderList = _ObserveArray(value, this._renderListHasChanged);
    }
    this._renderList = value;
  }
  /**
   * Post-processes for this render target
   */
  get postProcesses() {
    return this._postProcesses;
  }
  get _prePassEnabled() {
    return !!this._prePassRenderTarget && this._prePassRenderTarget.enabled;
  }
  /**
   * Set a after unbind callback in the texture.
   * This has been kept for backward compatibility and use of onAfterUnbindObservable is recommended.
   */
  set onAfterUnbind(callback) {
    if (this._onAfterUnbindObserver) {
      this.onAfterUnbindObservable.remove(this._onAfterUnbindObserver);
    }
    this._onAfterUnbindObserver = this.onAfterUnbindObservable.add(callback);
  }
  /**
   * Set a before render callback in the texture.
   * This has been kept for backward compatibility and use of onBeforeRenderObservable is recommended.
   */
  set onBeforeRender(callback) {
    if (this._onBeforeRenderObserver) {
      this.onBeforeRenderObservable.remove(this._onBeforeRenderObserver);
    }
    this._onBeforeRenderObserver = this.onBeforeRenderObservable.add(callback);
  }
  /**
   * Set a after render callback in the texture.
   * This has been kept for backward compatibility and use of onAfterRenderObservable is recommended.
   */
  set onAfterRender(callback) {
    if (this._onAfterRenderObserver) {
      this.onAfterRenderObservable.remove(this._onAfterRenderObserver);
    }
    this._onAfterRenderObserver = this.onAfterRenderObservable.add(callback);
  }
  /**
   * Set a clear callback in the texture.
   * This has been kept for backward compatibility and use of onClearObservable is recommended.
   */
  set onClear(callback) {
    if (this._onClearObserver) {
      this.onClearObservable.remove(this._onClearObserver);
    }
    this._onClearObserver = this.onClearObservable.add(callback);
  }
  /**
   * Gets the render pass ids used by the render target texture. For a single render target the array length will be 1, for a cube texture it will be 6 and for
   * a 2D texture array it will return an array of ids the size of the 2D texture array
   */
  get renderPassIds() {
    return this._renderPassIds;
  }
  /**
   * Gets the current value of the refreshId counter
   */
  get currentRefreshId() {
    return this._currentRefreshId;
  }
  /**
   * Sets a specific material to be used to render a mesh/a list of meshes in this render target texture
   * @param mesh mesh or array of meshes
   * @param material material or array of materials to use for this render pass. If undefined is passed, no specific material will be used but the regular material instead (mesh.material). It's possible to provide an array of materials to use a different material for each rendering in the case of a cube texture (6 rendering) and a 2D texture array (as many rendering as the length of the array)
   */
  setMaterialForRendering(mesh, material) {
    let meshes;
    if (!Array.isArray(mesh)) {
      meshes = [mesh];
    } else {
      meshes = mesh;
    }
    for (let j = 0; j < meshes.length; ++j) {
      for (let i = 0; i < this._renderPassIds.length; ++i) {
        meshes[j].setMaterialForRenderPass(this._renderPassIds[i], material !== void 0 ? Array.isArray(material) ? material[i] : material : void 0);
      }
    }
  }
  /**
   * Define if the texture has multiple draw buffers or if false a single draw buffer.
   */
  get isMulti() {
    var _a;
    return ((_a = this._renderTarget) == null ? void 0 : _a.isMulti) ?? false;
  }
  /**
   * Gets render target creation options that were used.
   */
  get renderTargetOptions() {
    return this._renderTargetOptions;
  }
  /**
   * Gets the render target wrapper associated with this render target
   */
  get renderTarget() {
    return this._renderTarget;
  }
  _onRatioRescale() {
    if (this._sizeRatio) {
      this.resize(this._initialSizeParameter);
    }
  }
  /**
   * Gets or sets the size of the bounding box associated with the texture (when in cube mode)
   * When defined, the cubemap will switch to local mode
   * @see https://community.arm.com/graphics/b/blog/posts/reflections-based-on-local-cubemaps-in-unity
   * @example https://www.babylonjs-playground.com/#RNASML
   */
  set boundingBoxSize(value) {
    if (this._boundingBoxSize && this._boundingBoxSize.equals(value)) {
      return;
    }
    this._boundingBoxSize = value;
    const scene = this.getScene();
    if (scene) {
      scene.markAllMaterialsAsDirty(1);
    }
  }
  get boundingBoxSize() {
    return this._boundingBoxSize;
  }
  /**
   * In case the RTT has been created with a depth texture, get the associated
   * depth texture.
   * Otherwise, return null.
   */
  get depthStencilTexture() {
    var _a;
    return ((_a = this._renderTarget) == null ? void 0 : _a._depthStencilTexture) ?? null;
  }
  /** @internal */
  constructor(name, size, scene, generateMipMaps = false, doNotChangeAspectRatio = true, type = 0, isCube = false, samplingMode = Texture.TRILINEAR_SAMPLINGMODE, generateDepthBuffer = true, generateStencilBuffer = false, isMulti = false, format = 5, delayAllocation = false, samples, creationFlags, noColorAttachment = false, useSRGBBuffer = false) {
    let colorAttachment = void 0;
    let gammaSpace = true;
    if (typeof generateMipMaps === "object") {
      const options = generateMipMaps;
      generateMipMaps = !!options.generateMipMaps;
      doNotChangeAspectRatio = options.doNotChangeAspectRatio ?? true;
      type = options.type ?? 0;
      isCube = !!options.isCube;
      samplingMode = options.samplingMode ?? Texture.TRILINEAR_SAMPLINGMODE;
      generateDepthBuffer = options.generateDepthBuffer ?? true;
      generateStencilBuffer = !!options.generateStencilBuffer;
      isMulti = !!options.isMulti;
      format = options.format ?? 5;
      delayAllocation = !!options.delayAllocation;
      samples = options.samples;
      creationFlags = options.creationFlags;
      noColorAttachment = !!options.noColorAttachment;
      useSRGBBuffer = !!options.useSRGBBuffer;
      colorAttachment = options.colorAttachment;
      gammaSpace = options.gammaSpace ?? gammaSpace;
    }
    super(null, scene, !generateMipMaps, void 0, samplingMode, void 0, void 0, void 0, void 0, format);
    this._unObserveRenderList = null;
    this._renderListHasChanged = (_functionName, previousLength) => {
      var _a;
      const newLength = this._renderList ? this._renderList.length : 0;
      if (previousLength === 0 && newLength > 0 || newLength === 0) {
        (_a = this.getScene()) == null ? void 0 : _a.meshes.forEach((mesh) => {
          mesh._markSubMeshesAsLightDirty();
        });
      }
    };
    this.renderParticles = true;
    this.renderSprites = false;
    this.forceLayerMaskCheck = false;
    this.ignoreCameraViewport = false;
    this.onBeforeBindObservable = new Observable();
    this.onAfterUnbindObservable = new Observable();
    this.onBeforeRenderObservable = new Observable();
    this.onAfterRenderObservable = new Observable();
    this.onClearObservable = new Observable();
    this.onResizeObservable = new Observable();
    this._cleared = false;
    this.skipInitialClear = false;
    this._currentRefreshId = -1;
    this._refreshRate = 1;
    this._samples = 1;
    this._canRescale = true;
    this._renderTarget = null;
    this.boundingBoxPosition = Vector3.Zero();
    this._dumpToolsLoading = false;
    scene = this.getScene();
    if (!scene) {
      return;
    }
    const engine = this.getScene().getEngine();
    this._gammaSpace = gammaSpace;
    this._coordinatesMode = Texture.PROJECTION_MODE;
    this.renderList = [];
    this.name = name;
    this.isRenderTarget = true;
    this._initialSizeParameter = size;
    this._renderPassIds = [];
    this._isCubeData = isCube;
    this._processSizeParameter(size);
    this.renderPassId = this._renderPassIds[0];
    this._resizeObserver = engine.onResizeObservable.add(() => {
    });
    this._generateMipMaps = generateMipMaps ? true : false;
    this._doNotChangeAspectRatio = doNotChangeAspectRatio;
    this._renderingManager = new RenderingManager(scene);
    this._renderingManager._useSceneAutoClearSetup = true;
    if (isMulti) {
      return;
    }
    this._renderTargetOptions = {
      generateMipMaps,
      type,
      format: this._format ?? void 0,
      samplingMode: this.samplingMode,
      generateDepthBuffer,
      generateStencilBuffer,
      samples,
      creationFlags,
      noColorAttachment,
      useSRGBBuffer,
      colorAttachment,
      label: this.name
    };
    if (this.samplingMode === Texture.NEAREST_SAMPLINGMODE) {
      this.wrapU = Texture.CLAMP_ADDRESSMODE;
      this.wrapV = Texture.CLAMP_ADDRESSMODE;
    }
    if (!delayAllocation) {
      if (isCube) {
        this._renderTarget = scene.getEngine().createRenderTargetCubeTexture(this.getRenderSize(), this._renderTargetOptions);
        this.coordinatesMode = Texture.INVCUBIC_MODE;
        this._textureMatrix = Matrix.Identity();
      } else {
        this._renderTarget = scene.getEngine().createRenderTargetTexture(this._size, this._renderTargetOptions);
      }
      this._texture = this._renderTarget.texture;
      if (samples !== void 0) {
        this.samples = samples;
      }
    }
  }
  /**
   * Creates a depth stencil texture.
   * This is only available in WebGL 2 or with the depth texture extension available.
   * @param comparisonFunction Specifies the comparison function to set on the texture. If 0 or undefined, the texture is not in comparison mode (default: 0)
   * @param bilinearFiltering Specifies whether or not bilinear filtering is enable on the texture (default: true)
   * @param generateStencil Specifies whether or not a stencil should be allocated in the texture (default: false)
   * @param samples sample count of the depth/stencil texture (default: 1)
   * @param format format of the depth texture (default: 14)
   * @param label defines the label of the texture (for debugging purpose)
   */
  createDepthStencilTexture(comparisonFunction = 0, bilinearFiltering = true, generateStencil = false, samples = 1, format = 14, label) {
    var _a;
    (_a = this._renderTarget) == null ? void 0 : _a.createDepthStencilTexture(comparisonFunction, bilinearFiltering, generateStencil, samples, format, label);
  }
  _releaseRenderPassId() {
    if (this._scene) {
      const engine = this._scene.getEngine();
      for (let i = 0; i < this._renderPassIds.length; ++i) {
        engine.releaseRenderPassId(this._renderPassIds[i]);
      }
    }
    this._renderPassIds = [];
  }
  _createRenderPassId() {
    this._releaseRenderPassId();
    const engine = this._scene.getEngine();
    const numPasses = this._isCubeData ? 6 : this.getRenderLayers() || 1;
    for (let i = 0; i < numPasses; ++i) {
      this._renderPassIds[i] = engine.createRenderPassId(`RenderTargetTexture - ${this.name}#${i}`);
    }
  }
  _processSizeParameter(size, createRenderPassIds = true) {
    if (size.ratio) {
      this._sizeRatio = size.ratio;
      const engine = this._getEngine();
      this._size = {
        width: this._bestReflectionRenderTargetDimension(engine.getRenderWidth(), this._sizeRatio),
        height: this._bestReflectionRenderTargetDimension(engine.getRenderHeight(), this._sizeRatio)
      };
    } else {
      this._size = size;
    }
    if (createRenderPassIds) {
      this._createRenderPassId();
    }
  }
  /**
   * Define the number of samples to use in case of MSAA.
   * It defaults to one meaning no MSAA has been enabled.
   */
  get samples() {
    var _a;
    return ((_a = this._renderTarget) == null ? void 0 : _a.samples) ?? this._samples;
  }
  set samples(value) {
    if (this._renderTarget) {
      this._samples = this._renderTarget.setSamples(value);
    }
  }
  /**
   * Resets the refresh counter of the texture and start bak from scratch.
   * Could be useful to regenerate the texture if it is setup to render only once.
   */
  resetRefreshCounter() {
    this._currentRefreshId = -1;
  }
  /**
   * Define the refresh rate of the texture or the rendering frequency.
   * Use 0 to render just once, 1 to render on every frame, 2 to render every two frames and so on...
   */
  get refreshRate() {
    return this._refreshRate;
  }
  set refreshRate(value) {
    this._refreshRate = value;
    this.resetRefreshCounter();
  }
  /**
   * Adds a post process to the render target rendering passes.
   * @param postProcess define the post process to add
   */
  addPostProcess(postProcess) {
    if (!this._postProcessManager) {
      const scene = this.getScene();
      if (!scene) {
        return;
      }
      this._postProcessManager = new PostProcessManager(scene);
      this._postProcesses = new Array();
    }
    this._postProcesses.push(postProcess);
    this._postProcesses[0].autoClear = false;
  }
  /**
   * Clear all the post processes attached to the render target
   * @param dispose define if the cleared post processes should also be disposed (false by default)
   */
  clearPostProcesses(dispose = false) {
    if (!this._postProcesses) {
      return;
    }
    if (dispose) {
      for (const postProcess of this._postProcesses) {
        postProcess.dispose();
      }
    }
    this._postProcesses = [];
  }
  /**
   * Remove one of the post process from the list of attached post processes to the texture
   * @param postProcess define the post process to remove from the list
   */
  removePostProcess(postProcess) {
    if (!this._postProcesses) {
      return;
    }
    const index = this._postProcesses.indexOf(postProcess);
    if (index === -1) {
      return;
    }
    this._postProcesses.splice(index, 1);
    if (this._postProcesses.length > 0) {
      this._postProcesses[0].autoClear = false;
    }
  }
  /** @internal */
  _shouldRender() {
    if (this._currentRefreshId === -1) {
      this._currentRefreshId = 1;
      return true;
    }
    if (this.refreshRate === this._currentRefreshId) {
      this._currentRefreshId = 1;
      return true;
    }
    this._currentRefreshId++;
    return false;
  }
  /**
   * Gets the actual render size of the texture.
   * @returns the width of the render size
   */
  getRenderSize() {
    return this.getRenderWidth();
  }
  /**
   * Gets the actual render width of the texture.
   * @returns the width of the render size
   */
  getRenderWidth() {
    if (this._size.width) {
      return this._size.width;
    }
    return this._size;
  }
  /**
   * Gets the actual render height of the texture.
   * @returns the height of the render size
   */
  getRenderHeight() {
    if (this._size.width) {
      return this._size.height;
    }
    return this._size;
  }
  /**
   * Gets the actual number of layers of the texture or, in the case of a 3D texture, return the depth.
   * @returns the number of layers
   */
  getRenderLayers() {
    const layers = this._size.layers;
    if (layers) {
      return layers;
    }
    const depth = this._size.depth;
    if (depth) {
      return depth;
    }
    return 0;
  }
  /**
   * Don't allow this render target texture to rescale. Mainly used to prevent rescaling by the scene optimizer.
   */
  disableRescaling() {
    this._canRescale = false;
  }
  /**
   * Get if the texture can be rescaled or not.
   */
  get canRescale() {
    return this._canRescale;
  }
  /**
   * Resize the texture using a ratio.
   * @param ratio the ratio to apply to the texture size in order to compute the new target size
   */
  scale(ratio) {
    const newSize = Math.max(1, this.getRenderSize() * ratio);
    this.resize(newSize);
  }
  /**
   * Get the texture reflection matrix used to rotate/transform the reflection.
   * @returns the reflection matrix
   */
  getReflectionTextureMatrix() {
    if (this.isCube) {
      return this._textureMatrix;
    }
    return super.getReflectionTextureMatrix();
  }
  /**
   * Resize the texture to a new desired size.
   * Be careful as it will recreate all the data in the new texture.
   * @param size Define the new size. It can be:
   *   - a number for squared texture,
   *   - an object containing { width: number, height: number }
   *   - or an object containing a ratio { ratio: number }
   */
  resize(size) {
    var _a;
    const wasCube = this.isCube;
    (_a = this._renderTarget) == null ? void 0 : _a.dispose();
    this._renderTarget = null;
    const scene = this.getScene();
    if (!scene) {
      return;
    }
    this._processSizeParameter(size, false);
    if (wasCube) {
      this._renderTarget = scene.getEngine().createRenderTargetCubeTexture(this.getRenderSize(), this._renderTargetOptions);
    } else {
      this._renderTarget = scene.getEngine().createRenderTargetTexture(this._size, this._renderTargetOptions);
    }
    this._texture = this._renderTarget.texture;
    if (this._renderTargetOptions.samples !== void 0) {
      this.samples = this._renderTargetOptions.samples;
    }
    if (this.onResizeObservable.hasObservers()) {
      this.onResizeObservable.notifyObservers(this);
    }
  }
  /**
   * Renders all the objects from the render list into the texture.
   * @param useCameraPostProcess Define if camera post processes should be used during the rendering
   * @param dumpForDebug Define if the rendering result should be dumped (copied) for debugging purpose
   */
  render(useCameraPostProcess = false, dumpForDebug = false) {
    this._render(useCameraPostProcess, dumpForDebug);
  }
  /**
   * This function will check if the render target texture can be rendered (textures are loaded, shaders are compiled)
   * @returns true if all required resources are ready
   */
  isReadyForRendering() {
    if (!this._dumpToolsLoading) {
      this._dumpToolsLoading = true;
      import("./dumpTools-CZMDPVF2.js").then((module) => this._dumpTools = module);
    }
    return this._render(false, false, true);
  }
  _render(useCameraPostProcess = false, dumpForDebug = false, checkReadiness = false) {
    const scene = this.getScene();
    if (!scene) {
      return checkReadiness;
    }
    const engine = scene.getEngine();
    if (this.useCameraPostProcesses !== void 0) {
      useCameraPostProcess = this.useCameraPostProcesses;
    }
    if (this._waitingRenderList) {
      if (!this.renderListPredicate) {
        this.renderList = [];
        for (let index = 0; index < this._waitingRenderList.length; index++) {
          const id = this._waitingRenderList[index];
          const mesh = scene.getMeshById(id);
          if (mesh) {
            this.renderList.push(mesh);
          }
        }
      }
      this._waitingRenderList = void 0;
    }
    if (this.renderListPredicate) {
      if (this.renderList) {
        this.renderList.length = 0;
      } else {
        this.renderList = [];
      }
      const scene2 = this.getScene();
      if (!scene2) {
        return checkReadiness;
      }
      const sceneMeshes = scene2.meshes;
      for (let index = 0; index < sceneMeshes.length; index++) {
        const mesh = sceneMeshes[index];
        if (this.renderListPredicate(mesh)) {
          this.renderList.push(mesh);
        }
      }
    }
    const currentRenderPassId = engine.currentRenderPassId;
    this.onBeforeBindObservable.notifyObservers(this);
    const camera = this.activeCamera ?? scene.activeCamera;
    const sceneCamera = scene.activeCamera;
    if (camera) {
      if (camera !== scene.activeCamera) {
        scene.setTransformMatrix(camera.getViewMatrix(), camera.getProjectionMatrix(true));
        scene.activeCamera = camera;
      }
      engine.setViewport(camera.rigParent ? camera.rigParent.viewport : camera.viewport, this.getRenderWidth(), this.getRenderHeight());
    }
    this._defaultRenderListPrepared = false;
    let returnValue = checkReadiness;
    if (!checkReadiness) {
      if ((this.is2DArray || this.is3D) && !this.isMulti) {
        for (let layer = 0; layer < this.getRenderLayers(); layer++) {
          this._renderToTarget(0, useCameraPostProcess, dumpForDebug, layer, camera);
          scene.incrementRenderId();
          scene.resetCachedMaterial();
        }
      } else if (this.isCube && !this.isMulti) {
        for (let face = 0; face < 6; face++) {
          this._renderToTarget(face, useCameraPostProcess, dumpForDebug, void 0, camera);
          scene.incrementRenderId();
          scene.resetCachedMaterial();
        }
      } else {
        this._renderToTarget(0, useCameraPostProcess, dumpForDebug, void 0, camera);
      }
    } else {
      if (!scene.getViewMatrix()) {
        scene.updateTransformMatrix();
      }
      const numLayers = this.is2DArray || this.is3D ? this.getRenderLayers() : this.isCube ? 6 : 1;
      for (let layer = 0; layer < numLayers && returnValue; layer++) {
        let currentRenderList = null;
        const defaultRenderList = this.renderList ? this.renderList : scene.getActiveMeshes().data;
        const defaultRenderListLength = this.renderList ? this.renderList.length : scene.getActiveMeshes().length;
        engine.currentRenderPassId = this._renderPassIds[layer];
        this.onBeforeRenderObservable.notifyObservers(layer);
        if (this.getCustomRenderList) {
          currentRenderList = this.getCustomRenderList(layer, defaultRenderList, defaultRenderListLength);
        }
        if (!currentRenderList) {
          currentRenderList = defaultRenderList;
        }
        if (!this._doNotChangeAspectRatio) {
          scene.updateTransformMatrix(true);
        }
        for (let i = 0; i < currentRenderList.length && returnValue; ++i) {
          const mesh = currentRenderList[i];
          if (!mesh.isEnabled() || mesh.isBlocked || !mesh.isVisible || !mesh.subMeshes) {
            continue;
          }
          if (this.customIsReadyFunction) {
            if (!this.customIsReadyFunction(mesh, this.refreshRate, checkReadiness)) {
              returnValue = false;
              continue;
            }
          } else if (!mesh.isReady(true)) {
            returnValue = false;
            continue;
          }
        }
        this.onAfterRenderObservable.notifyObservers(layer);
        if (this.is2DArray || this.is3D || this.isCube) {
          scene.incrementRenderId();
          scene.resetCachedMaterial();
        }
      }
    }
    this.onAfterUnbindObservable.notifyObservers(this);
    engine.currentRenderPassId = currentRenderPassId;
    if (sceneCamera) {
      scene.activeCamera = sceneCamera;
      if (this.activeCamera && this.activeCamera !== scene.activeCamera) {
        scene.setTransformMatrix(scene.activeCamera.getViewMatrix(), scene.activeCamera.getProjectionMatrix(true));
      }
      engine.setViewport(scene.activeCamera.viewport);
    }
    scene.resetCachedMaterial();
    return returnValue;
  }
  _bestReflectionRenderTargetDimension(renderDimension, scale) {
    const minimum = 128;
    const x = renderDimension * scale;
    const curved = NearestPOT(x + minimum * minimum / (minimum + x));
    return Math.min(FloorPOT(renderDimension), curved);
  }
  _prepareRenderingManager(currentRenderList, currentRenderListLength, camera, checkLayerMask) {
    const scene = this.getScene();
    if (!scene) {
      return;
    }
    this._renderingManager.reset();
    const sceneRenderId = scene.getRenderId();
    for (let meshIndex = 0; meshIndex < currentRenderListLength; meshIndex++) {
      const mesh = currentRenderList[meshIndex];
      if (mesh && !mesh.isBlocked) {
        if (this.customIsReadyFunction) {
          if (!this.customIsReadyFunction(mesh, this.refreshRate, false)) {
            this.resetRefreshCounter();
            continue;
          }
        } else if (!mesh.isReady(this.refreshRate === 0)) {
          this.resetRefreshCounter();
          continue;
        }
        if (!mesh._internalAbstractMeshDataInfo._currentLODIsUpToDate && scene.activeCamera) {
          mesh._internalAbstractMeshDataInfo._currentLOD = scene.customLODSelector ? scene.customLODSelector(mesh, this.activeCamera || scene.activeCamera) : mesh.getLOD(this.activeCamera || scene.activeCamera);
          mesh._internalAbstractMeshDataInfo._currentLODIsUpToDate = true;
        }
        if (!mesh._internalAbstractMeshDataInfo._currentLOD) {
          continue;
        }
        let meshToRender = mesh._internalAbstractMeshDataInfo._currentLOD;
        meshToRender._preActivateForIntermediateRendering(sceneRenderId);
        let isMasked;
        if (checkLayerMask && camera) {
          isMasked = (mesh.layerMask & camera.layerMask) === 0;
        } else {
          isMasked = false;
        }
        if (mesh.isEnabled() && mesh.isVisible && mesh.subMeshes && !isMasked) {
          if (meshToRender !== mesh) {
            meshToRender._activate(sceneRenderId, true);
          }
          if (mesh._activate(sceneRenderId, true) && mesh.subMeshes.length) {
            if (!mesh.isAnInstance) {
              meshToRender._internalAbstractMeshDataInfo._onlyForInstancesIntermediate = false;
            } else {
              if (mesh._internalAbstractMeshDataInfo._actAsRegularMesh) {
                meshToRender = mesh;
              }
            }
            meshToRender._internalAbstractMeshDataInfo._isActiveIntermediate = true;
            for (let subIndex = 0; subIndex < meshToRender.subMeshes.length; subIndex++) {
              const subMesh = meshToRender.subMeshes[subIndex];
              this._renderingManager.dispatch(subMesh, meshToRender);
            }
          }
          mesh._postActivate();
        }
      }
    }
    for (let particleIndex = 0; particleIndex < scene.particleSystems.length; particleIndex++) {
      const particleSystem = scene.particleSystems[particleIndex];
      const emitter = particleSystem.emitter;
      if (!particleSystem.isStarted() || !emitter || emitter.position && !emitter.isEnabled()) {
        continue;
      }
      this._renderingManager.dispatchParticles(particleSystem);
    }
  }
  /**
   * @internal
   * @param faceIndex face index to bind to if this is a cubetexture
   * @param layer defines the index of the texture to bind in the array
   */
  _bindFrameBuffer(faceIndex = 0, layer = 0) {
    const scene = this.getScene();
    if (!scene) {
      return;
    }
    const engine = scene.getEngine();
    if (this._renderTarget) {
      engine.bindFramebuffer(this._renderTarget, this.isCube ? faceIndex : void 0, void 0, void 0, this.ignoreCameraViewport, 0, layer);
    }
  }
  _unbindFrameBuffer(engine, faceIndex) {
    if (!this._renderTarget) {
      return;
    }
    engine.unBindFramebuffer(this._renderTarget, this.isCube, () => {
      this.onAfterRenderObservable.notifyObservers(faceIndex);
    });
  }
  /**
   * @internal
   */
  _prepareFrame(scene, faceIndex, layer, useCameraPostProcess) {
    if (this._postProcessManager) {
      if (!this._prePassEnabled) {
        this._postProcessManager._prepareFrame(this._texture, this._postProcesses);
      }
    } else if (!useCameraPostProcess || !scene.postProcessManager._prepareFrame(this._texture)) {
      this._bindFrameBuffer(faceIndex, layer);
    }
  }
  _renderToTarget(faceIndex, useCameraPostProcess, dumpForDebug, layer = 0, camera = null) {
    var _a, _b;
    const scene = this.getScene();
    if (!scene) {
      return;
    }
    const engine = scene.getEngine();
    this._prepareFrame(scene, faceIndex, layer, useCameraPostProcess);
    (_a = engine._debugInsertMarker) == null ? void 0 : _a.call(engine, `render to face #${faceIndex} layer #${layer}`);
    if (this.is2DArray || this.is3D) {
      engine.currentRenderPassId = this._renderPassIds[layer];
      this.onBeforeRenderObservable.notifyObservers(layer);
    } else {
      engine.currentRenderPassId = this._renderPassIds[faceIndex];
      this.onBeforeRenderObservable.notifyObservers(faceIndex);
    }
    const fastPath = engine.snapshotRendering && engine.snapshotRenderingMode === 1;
    if (!fastPath) {
      let currentRenderList = null;
      const defaultRenderList = this.renderList ? this.renderList : scene.getActiveMeshes().data;
      const defaultRenderListLength = this.renderList ? this.renderList.length : scene.getActiveMeshes().length;
      if (this.getCustomRenderList) {
        currentRenderList = this.getCustomRenderList(this.is2DArray || this.is3D ? layer : faceIndex, defaultRenderList, defaultRenderListLength);
      }
      if (!currentRenderList) {
        if (!this._defaultRenderListPrepared) {
          this._prepareRenderingManager(defaultRenderList, defaultRenderListLength, camera, !this.renderList || this.forceLayerMaskCheck);
          this._defaultRenderListPrepared = true;
        }
        currentRenderList = defaultRenderList;
      } else {
        this._prepareRenderingManager(currentRenderList, currentRenderList.length, camera, this.forceLayerMaskCheck);
      }
      for (const step of scene._beforeRenderTargetClearStage) {
        step.action(this, faceIndex, layer);
      }
      if (this.onClearObservable.hasObservers()) {
        this.onClearObservable.notifyObservers(engine);
      } else if (!this.skipInitialClear) {
        engine.clear(this.clearColor || scene.clearColor, true, true, true);
      }
      if (!this._doNotChangeAspectRatio) {
        scene.updateTransformMatrix(true);
      }
      for (const step of scene._beforeRenderTargetDrawStage) {
        step.action(this, faceIndex, layer);
      }
      this._renderingManager.render(this.customRenderFunction, currentRenderList, this.renderParticles, this.renderSprites);
      for (const step of scene._afterRenderTargetDrawStage) {
        step.action(this, faceIndex, layer);
      }
      const saveGenerateMipMaps = ((_b = this._texture) == null ? void 0 : _b.generateMipMaps) ?? false;
      if (this._texture) {
        this._texture.generateMipMaps = false;
      }
      if (this._postProcessManager) {
        this._postProcessManager._finalizeFrame(false, this._renderTarget ?? void 0, faceIndex, this._postProcesses, this.ignoreCameraViewport);
      } else if (useCameraPostProcess) {
        scene.postProcessManager._finalizeFrame(false, this._renderTarget ?? void 0, faceIndex);
      }
      for (const step of scene._afterRenderTargetPostProcessStage) {
        step.action(this, faceIndex, layer);
      }
      if (this._texture) {
        this._texture.generateMipMaps = saveGenerateMipMaps;
      }
      if (!this._doNotChangeAspectRatio) {
        scene.updateTransformMatrix(true);
      }
      if (dumpForDebug) {
        if (!this._dumpTools) {
          Logger.Error("dumpTools module is still being loaded. To speed up the process import dump tools directly in your project");
        } else {
          this._dumpTools.DumpFramebuffer(this.getRenderWidth(), this.getRenderHeight(), engine);
        }
      }
    } else {
      if (this.onClearObservable.hasObservers()) {
        this.onClearObservable.notifyObservers(engine);
      } else {
        if (!this.skipInitialClear) {
          engine.clear(this.clearColor || scene.clearColor, true, true, true);
        }
      }
    }
    this._unbindFrameBuffer(engine, faceIndex);
    if (this._texture && this.isCube && faceIndex === 5) {
      engine.generateMipMapsForCubemap(this._texture, true);
    }
  }
  /**
   * Overrides the default sort function applied in the rendering group to prepare the meshes.
   * This allowed control for front to back rendering or reversely depending of the special needs.
   *
   * @param renderingGroupId The rendering group id corresponding to its index
   * @param opaqueSortCompareFn The opaque queue comparison function use to sort.
   * @param alphaTestSortCompareFn The alpha test queue comparison function use to sort.
   * @param transparentSortCompareFn The transparent queue comparison function use to sort.
   */
  setRenderingOrder(renderingGroupId, opaqueSortCompareFn = null, alphaTestSortCompareFn = null, transparentSortCompareFn = null) {
    this._renderingManager.setRenderingOrder(renderingGroupId, opaqueSortCompareFn, alphaTestSortCompareFn, transparentSortCompareFn);
  }
  /**
   * Specifies whether or not the stencil and depth buffer are cleared between two rendering groups.
   *
   * @param renderingGroupId The rendering group id corresponding to its index
   * @param autoClearDepthStencil Automatically clears depth and stencil between groups if true.
   */
  setRenderingAutoClearDepthStencil(renderingGroupId, autoClearDepthStencil) {
    this._renderingManager.setRenderingAutoClearDepthStencil(renderingGroupId, autoClearDepthStencil);
    this._renderingManager._useSceneAutoClearSetup = false;
  }
  /**
   * Clones the texture.
   * @returns the cloned texture
   */
  clone() {
    const textureSize = this.getSize();
    const newTexture = new _RenderTargetTexture(this.name, textureSize, this.getScene(), this._renderTargetOptions.generateMipMaps, this._doNotChangeAspectRatio, this._renderTargetOptions.type, this.isCube, this._renderTargetOptions.samplingMode, this._renderTargetOptions.generateDepthBuffer, this._renderTargetOptions.generateStencilBuffer, void 0, this._renderTargetOptions.format, void 0, this._renderTargetOptions.samples);
    newTexture.hasAlpha = this.hasAlpha;
    newTexture.level = this.level;
    newTexture.coordinatesMode = this.coordinatesMode;
    if (this.renderList) {
      newTexture.renderList = this.renderList.slice(0);
    }
    return newTexture;
  }
  /**
   * Serialize the texture to a JSON representation we can easily use in the respective Parse function.
   * @returns The JSON representation of the texture
   */
  serialize() {
    if (!this.name) {
      return null;
    }
    const serializationObject = super.serialize();
    serializationObject.renderTargetSize = this.getRenderSize();
    serializationObject.renderList = [];
    if (this.renderList) {
      for (let index = 0; index < this.renderList.length; index++) {
        serializationObject.renderList.push(this.renderList[index].id);
      }
    }
    return serializationObject;
  }
  /**
   *  This will remove the attached framebuffer objects. The texture will not be able to be used as render target anymore
   */
  disposeFramebufferObjects() {
    var _a;
    (_a = this._renderTarget) == null ? void 0 : _a.dispose(true);
  }
  /**
   * Release and destroy the underlying lower level texture aka internalTexture.
   */
  releaseInternalTexture() {
    var _a;
    (_a = this._renderTarget) == null ? void 0 : _a.releaseTextures();
    this._texture = null;
  }
  /**
   * Dispose the texture and release its associated resources.
   */
  dispose() {
    var _a;
    this.onResizeObservable.clear();
    this.onClearObservable.clear();
    this.onAfterRenderObservable.clear();
    this.onAfterUnbindObservable.clear();
    this.onBeforeBindObservable.clear();
    this.onBeforeRenderObservable.clear();
    if (this._postProcessManager) {
      this._postProcessManager.dispose();
      this._postProcessManager = null;
    }
    if (this._prePassRenderTarget) {
      this._prePassRenderTarget.dispose();
    }
    this._releaseRenderPassId();
    this.clearPostProcesses(true);
    if (this._resizeObserver) {
      this.getScene().getEngine().onResizeObservable.remove(this._resizeObserver);
      this._resizeObserver = null;
    }
    this.renderList = null;
    const scene = this.getScene();
    if (!scene) {
      return;
    }
    let index = scene.customRenderTargets.indexOf(this);
    if (index >= 0) {
      scene.customRenderTargets.splice(index, 1);
    }
    for (const camera of scene.cameras) {
      index = camera.customRenderTargets.indexOf(this);
      if (index >= 0) {
        camera.customRenderTargets.splice(index, 1);
      }
    }
    (_a = this._renderTarget) == null ? void 0 : _a.dispose();
    this._renderTarget = null;
    this._texture = null;
    super.dispose();
  }
  /** @internal */
  _rebuild() {
    if (this.refreshRate === _RenderTargetTexture.REFRESHRATE_RENDER_ONCE) {
      this.refreshRate = _RenderTargetTexture.REFRESHRATE_RENDER_ONCE;
    }
    if (this._postProcessManager) {
      this._postProcessManager._rebuild();
    }
  }
  /**
   * Clear the info related to rendering groups preventing retention point in material dispose.
   */
  freeRenderingGroups() {
    if (this._renderingManager) {
      this._renderingManager.freeRenderingGroups();
    }
  }
  /**
   * Gets the number of views the corresponding to the texture (eg. a MultiviewRenderTarget will have > 1)
   * @returns the view count
   */
  getViewCount() {
    return 1;
  }
};
RenderTargetTexture.REFRESHRATE_RENDER_ONCE = 0;
RenderTargetTexture.REFRESHRATE_RENDER_ONEVERYFRAME = 1;
RenderTargetTexture.REFRESHRATE_RENDER_ONEVERYTWOFRAMES = 2;
Texture._CreateRenderTargetTexture = (name, renderTargetSize, scene, generateMipMaps, creationFlags) => {
  return new RenderTargetTexture(name, renderTargetSize, scene, generateMipMaps);
};

// node_modules/@babylonjs/core/PostProcesses/passPostProcess.js
var PassPostProcess = class _PassPostProcess extends PostProcess {
  /**
   * Gets a string identifying the name of the class
   * @returns "PassPostProcess" string
   */
  getClassName() {
    return "PassPostProcess";
  }
  /**
   * Creates the PassPostProcess
   * @param name The name of the effect.
   * @param options The required width/height ratio to downsize to before computing the render pass.
   * @param camera The camera to apply the render pass to.
   * @param samplingMode The sampling mode to be used when computing the pass. (default: 0)
   * @param engine The engine which the post process will be applied. (default: current engine)
   * @param reusable If the post process can be reused on the same frame. (default: false)
   * @param textureType The type of texture to be used when performing the post processing.
   * @param blockCompilation If compilation of the shader should not be done in the constructor. The updateEffect method can be used to compile the shader at a later time. (default: false)
   */
  constructor(name, options, camera = null, samplingMode, engine, reusable, textureType = 0, blockCompilation = false) {
    super(name, "pass", null, null, options, camera, samplingMode, engine, reusable, void 0, textureType, void 0, null, blockCompilation);
  }
  _gatherImports(useWebGPU, list) {
    if (useWebGPU) {
      this._webGPUReady = true;
      list.push(Promise.all([import("./pass.fragment-7D6G72B4.js")]));
    } else {
      list.push(Promise.all([import("./pass.fragment-KOCN5MT7.js")]));
    }
    super._gatherImports(useWebGPU, list);
  }
  /**
   * @internal
   */
  static _Parse(parsedPostProcess, targetCamera, scene, rootUrl) {
    return SerializationHelper.Parse(() => {
      return new _PassPostProcess(parsedPostProcess.name, parsedPostProcess.options, targetCamera, parsedPostProcess.renderTargetSamplingMode, parsedPostProcess._engine, parsedPostProcess.reusable);
    }, parsedPostProcess, scene, rootUrl);
  }
};
RegisterClass("BABYLON.PassPostProcess", PassPostProcess);
AbstractEngine._RescalePostProcessFactory = (engine) => {
  return new PassPostProcess("rescale", 1, null, 2, engine, false, 0);
};

// node_modules/@babylonjs/core/Misc/textureTools.js
function ApplyPostProcess(postProcessName, internalTexture, scene, type, samplingMode, format, width, height) {
  const engine = internalTexture.getEngine();
  internalTexture.isReady = false;
  samplingMode = samplingMode ?? internalTexture.samplingMode;
  type = type ?? internalTexture.type;
  format = format ?? internalTexture.format;
  width = width ?? internalTexture.width;
  height = height ?? internalTexture.height;
  if (type === -1) {
    type = 0;
  }
  return new Promise((resolve) => {
    const postProcess = new PostProcess("postprocess", postProcessName, null, null, 1, null, samplingMode, engine, false, void 0, type, void 0, null, false, format);
    postProcess.externalTextureSamplerBinding = true;
    const encodedTexture = engine.createRenderTargetTexture({ width, height }, {
      generateDepthBuffer: false,
      generateMipMaps: false,
      generateStencilBuffer: false,
      samplingMode,
      type,
      format
    });
    postProcess.onEffectCreatedObservable.addOnce((e) => {
      e.executeWhenCompiled(() => {
        postProcess.onApply = (effect) => {
          effect._bindTexture("textureSampler", internalTexture);
          effect.setFloat2("scale", 1, 1);
        };
        scene.postProcessManager.directRender([postProcess], encodedTexture, true);
        engine.restoreDefaultFramebuffer();
        engine._releaseTexture(internalTexture);
        if (postProcess) {
          postProcess.dispose();
        }
        encodedTexture._swapAndDie(internalTexture);
        internalTexture.type = type;
        internalTexture.format = 5;
        internalTexture.isReady = true;
        resolve(internalTexture);
      });
    });
  });
}
var floatView;
var int32View;
function ToHalfFloat(value) {
  if (!floatView) {
    floatView = new Float32Array(1);
    int32View = new Int32Array(floatView.buffer);
  }
  floatView[0] = value;
  const x = int32View[0];
  let bits = x >> 16 & 32768;
  let m = x >> 12 & 2047;
  const e = x >> 23 & 255;
  if (e < 103) {
    return bits;
  }
  if (e > 142) {
    bits |= 31744;
    bits |= (e == 255 ? 0 : 1) && x & 8388607;
    return bits;
  }
  if (e < 113) {
    m |= 2048;
    bits |= (m >> 114 - e) + (m >> 113 - e & 1);
    return bits;
  }
  bits |= e - 112 << 10 | m >> 1;
  bits += m & 1;
  return bits;
}
function FromHalfFloat(value) {
  const s = (value & 32768) >> 15;
  const e = (value & 31744) >> 10;
  const f = value & 1023;
  if (e === 0) {
    return (s ? -1 : 1) * Math.pow(2, -14) * (f / Math.pow(2, 10));
  } else if (e == 31) {
    return f ? NaN : (s ? -1 : 1) * Infinity;
  }
  return (s ? -1 : 1) * Math.pow(2, e - 15) * (1 + f / Math.pow(2, 10));
}

export {
  SphericalHarmonics,
  SphericalPolynomial,
  CubeMapToSphericalPolynomialTools,
  RenderTargetTexture,
  PostProcess,
  ApplyPostProcess,
  ToHalfFloat,
  FromHalfFloat
};
//# sourceMappingURL=chunk-UUZIGHMZ.js.map
